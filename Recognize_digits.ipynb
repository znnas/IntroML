{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распознаем цифры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу включим всё, что использовали на лекции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "# np.random.seed(42)\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "\n",
    "IMAGE_TRAIN_PATH = \"./data/train/image\"\n",
    "VOICE_TRAIN_PATH = \"./data/train/voice\"\n",
    "IMAGE_TEST_PATH = \"./data/test/image/\"\n",
    "VOICE_TEST_PATH = \"./data/test/voice/\"\n",
    "\n",
    "def read_image(path):\n",
    "    return PIL.Image.open(path).convert('L')\n",
    "def load_wav(path):\n",
    "    return librosa.load(path, sr=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим модели и средства перекрёстной проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Извлечение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(image_folder):\n",
    "    image_vectors = []\n",
    "    indices = []\n",
    "    for image_name in os.listdir(image_folder):\n",
    "        index = os.path.splitext(image_name)[0]\n",
    "        indices.append(index)\n",
    "        image = read_image(os.path.join(image_folder, image_name))\n",
    "        image_vector = np.array(image).reshape(-1)\n",
    "        image_vectors.append(image_vector)\n",
    "    return pd.DataFrame({\n",
    "        'index': indices,\n",
    "        'image_vector': image_vectors,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = extract_image_features(IMAGE_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_10</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                       image_vector\n",
       "0   0_0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1   0_1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2  0_10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_voice_features(voice_folder, numcep=16, hop_length=256):\n",
    "    voice_vectors = []\n",
    "    indices = []\n",
    "    for record_name in os.listdir(voice_folder):\n",
    "        index = os.path.splitext(record_name)[0]\n",
    "        indices.append(index)\n",
    "        signal, sr = load_wav(\n",
    "            os.path.join(voice_folder, record_name)\n",
    "        )\n",
    "        mfcc_features = librosa.feature.mfcc(\n",
    "            signal, sr=sr, n_mfcc=numcep, hop_length=hop_length\n",
    "        )\n",
    "        voice_vector = mfcc_features.mean(axis=1)\n",
    "        voice_vectors.append(voice_vector)\n",
    "    return pd.DataFrame({\n",
    "        'index': indices,\n",
    "        'voice_vector': voice_vectors,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_features = extract_voice_features(VOICE_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>voice_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>[-206.83414255852185, 57.27340509868273, 17.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>[-219.53283419210226, 56.91259734891663, 35.57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_10</td>\n",
       "      <td>[-400.8118128999196, 54.28934451595202, 1.0990...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                       voice_vector\n",
       "0   0_0  [-206.83414255852185, 57.27340509868273, 17.93...\n",
       "1   0_1  [-219.53283419210226, 56.91259734891663, 35.57...\n",
       "2  0_10  [-400.8118128999196, 54.28934451595202, 1.0990..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = image_features.merge(voice_features, on='index')\n",
    "dataset[\"target\"] = dataset[\"index\"].apply(lambda x: int(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_vector</th>\n",
       "      <th>voice_vector</th>\n",
       "      <th>target</th>\n",
       "      <th>im_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-206.83414255852185, 57.27340509868273, 17.93...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 43, 145, 235, 235,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-219.53283419210226, 56.91259734891663, 35.57...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 47, 150, 253, 253, 63, 0, 0, 11, 155, 233,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_10</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-400.8118128999196, 54.28934451595202, 1.0990...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 20, 134, 253, 253, 255, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                       image_vector  \\\n",
       "0   0_0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1   0_1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  0_10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        voice_vector  target  \\\n",
       "0  [-206.83414255852185, 57.27340509868273, 17.93...       0   \n",
       "1  [-219.53283419210226, 56.91259734891663, 35.57...       0   \n",
       "2  [-400.8118128999196, 54.28934451595202, 1.0990...       0   \n",
       "\n",
       "                                            im_short  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 43, 145, 235, 235,...  \n",
       "1  [0, 47, 150, 253, 253, 63, 0, 0, 11, 155, 233,...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 20, 134, 253, 253, 255, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma=np.std(np.vstack(dataset[\"image_vector\"]), axis=0)\n",
    "dataset[\"im_short\"]=list(map(lambda x: np.extract(sigma>64,x),dataset[\"image_vector\"]))\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_vector</th>\n",
       "      <th>voice_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-314.85054916612467, 92.66636306282136, -20.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-379.8489601033069, 20.240626903812768, 27.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-176.60444192796464, 102.20920327426838, -18....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                       image_vector  \\\n",
       "0      0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        voice_vector  \n",
       "0  [-314.85054916612467, 92.66636306282136, -20.0...  \n",
       "1  [-379.8489601033069, 20.240626903812768, 27.49...  \n",
       "2  [-176.60444192796464, 102.20920327426838, -18....  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_image_features = extract_image_features(IMAGE_TEST_PATH)\n",
    "submit_voice_features = extract_voice_features(VOICE_TEST_PATH)\n",
    "submit_dataset = submit_image_features.merge(\n",
    "    submit_voice_features, \n",
    "    on=\"index\"\n",
    ")\n",
    "submit_dataset[\"index\"] = submit_dataset[\"index\"].apply(int)\n",
    "submit_dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Улучшим предсказание по звуку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [Здесь](https://habr.com/ru/post/140828/) сказано, что рекомендуется брать от 13 до 24 мел-частотных спектральных коэффициентов, но хороший результат начинается с 16. Значит формирование данных по первым 13 нас не устроит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9399188564794321 13\n",
      "0.945896802809022 14\n",
      "0.9472792260336262 15\n",
      "0.9511864081044171 16\n",
      "0.9585601601540678 17\n",
      "0.955908778198294 18\n",
      "0.959213657214893 19\n",
      "0.9605359159076242 20\n",
      "0.957902312519787 21\n",
      "0.9612714015211384 22\n",
      "0.9618983971870365 23\n"
     ]
    }
   ],
   "source": [
    "for i in range(13,24,1):\n",
    "    voice_features = extract_voice_features(VOICE_TRAIN_PATH, numcep=i)\n",
    "    X = np.vstack(voice_features[\"voice_vector\"])\n",
    "    y=dataset[\"target\"]\n",
    "    mdl_all = RandomForestClassifier(n_estimators=500)\n",
    "    print(np.mean(cross_val_score(mdl_all, X, y, cv=5, scoring='accuracy')), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём 20 коэффициентов. Теперь подберём размер случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9499166986605887 100\n",
      "0.9606088389625909 200\n",
      "0.9571956996600226 300\n",
      "0.9532264630328664 400\n",
      "0.95523112728242 500\n",
      "0.9599000667000052 600\n",
      "0.9579023580188112 700\n",
      "0.9565487165499086 800\n",
      "0.9585758782660998 900\n",
      "0.9612313948648932 1000\n"
     ]
    }
   ],
   "source": [
    "voice_features = extract_voice_features(VOICE_TRAIN_PATH, numcep=20)\n",
    "X = np.vstack(voice_features[\"voice_vector\"])\n",
    "y=dataset[\"target\"]\n",
    "    \n",
    "for i in range(100,1001,100):\n",
    "    mdl_all = RandomForestClassifier(n_estimators=i)\n",
    "    print(np.mean(cross_val_score(mdl_all, X, y, cv=5, scoring='accuracy')), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первой попыткой попробуем сдать улучшенное предсказание по звуку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cep=20;\n",
    "n_est=600;\n",
    "\n",
    "submit_image_features = extract_image_features(IMAGE_TEST_PATH)\n",
    "submit_voice_features = extract_voice_features(VOICE_TEST_PATH, numcep=n_cep)\n",
    "submit_dataset = submit_image_features.merge(\n",
    "    submit_voice_features, \n",
    "    on=\"index\"\n",
    ")\n",
    "submit_dataset[\"index\"] = submit_dataset[\"index\"].apply(int)\n",
    "\n",
    "voice_features = extract_voice_features(VOICE_TRAIN_PATH, numcep=n_cep)\n",
    "X = np.vstack(voice_features[\"voice_vector\"])\n",
    "y=dataset[\"target\"]\n",
    "\n",
    "mdlVo=RandomForestClassifier(n_estimators=n_est)\n",
    "mdlVo.fit(X,y)\n",
    "\n",
    "guess = mdlVo.predict(np.vstack(submit_voice_features[\"voice_vector\"]))\n",
    "submit_dataset[\"target\"] = guess\n",
    "\n",
    "submit_dataset[[\"index\", \"target\"]] \\\n",
    "    .sort_values(\"index\") \\\n",
    "    .to_csv(\"sub_goodvoice.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель по картинкам и извлечение наилучших признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(dataset[\"image_vector\"])\n",
    "y=dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим результаты работы леса. Отбирать факторы будем наипростейшим образом - по их важности в модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9074459973366105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_all = RandomForestClassifier(n_estimators=600)\n",
    "#mdlBo.fit(X, y)\n",
    "print(np.mean(cross_val_score(mdl_all, X, y, cv=5, scoring='accuracy')))\n",
    "mdl_all.fit(X,y)\n",
    "flag=mdl_all.feature_importances_>0.002\n",
    "np.sum(flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаков осталось слишком много, просто отрежем ещё."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag=mdl_all.feature_importances_>0.005\n",
    "np.sum(flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если эти признаки концентрируются на картинке в одно пятно, то лучше выбрать ругие признаки. Давайте просто увидим, что это не бусформенное пятно рядом стоящих пикселей из True. Пожалуй, сойдёт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19f149bd048>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((flag*255).reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Совместный учёт признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соединим признаки по голосу и указанные пиксели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"im_short\"]=list(map(lambda x: np.extract(mdl_all.feature_importances_>0.005,x),dataset[\"image_vector\"]))\n",
    "voice_features = extract_voice_features(VOICE_TRAIN_PATH, numcep=20)\n",
    "voice_features[\"new\"]= list(map(lambda x,y: np.concatenate((x, y), axis=0), \n",
    "                                voice_features[\"voice_vector\"], dataset[\"im_short\"]))\n",
    "X = np.vstack(voice_features[\"new\"])\n",
    "y=dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9325937613809903 100\n",
      "0.9360408429556099 200\n",
      "0.9387167788594908 300\n",
      "0.9347049800546434 400\n",
      "0.9353630078771129 500\n",
      "0.9379787832235552 600\n",
      "0.9386630827793049 700\n",
      "0.9386543242100667 800\n",
      "0.9386589441618508 900\n",
      "0.9373521381772573 1000\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,1001,100):\n",
    "    mdl_new = RandomForestClassifier(n_estimators=i)\n",
    "    print(np.mean(cross_val_score(mdl_new, X, y, cv=5, scoring='accuracy')), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью леса улучшения мы не добились. Ну что ж, попробуем бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9547758533411109 100\n",
      "0.9574139419915682 200\n",
      "0.956742801051971 300\n",
      "0.9567582042866501 400\n",
      "0.956751690335939 500\n",
      "0.9574139419915682 600\n",
      "0.9574139419915682 700\n",
      "0.9574139419915682 800\n",
      "0.9574139419915682 900\n",
      "0.9574139419915682 1000\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,1001,100):\n",
    "    mdl_new = GradientBoostingClassifier(n_estimators=i, learning_rate=0.1)\n",
    "    print(np.mean(cross_val_score(mdl_new, X, y, cv=5, scoring='accuracy')), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С ростом learning_rate как правило нужно меньшее количество шагов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9513889362983645 100\n",
      "0.949395536666036 200\n",
      "0.9507200399772943 300\n",
      "0.9513889362983645 400\n",
      "0.9513889362983645 500\n",
      "0.9507200399772943 600\n",
      "0.9507200399772943 700\n",
      "0.9500644329871063 800\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,801,100):\n",
    "    mdl_new = GradientBoostingClassifier(n_estimators=i, learning_rate=0.4)\n",
    "    print(np.mean(cross_val_score(mdl_new, X, y, cv=5, scoring='accuracy')), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется пикселей можно взять и побольше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"im_short\"]=list(map(lambda x: np.extract(mdl_all.feature_importances_>0.003,x),dataset[\"image_vector\"]))\n",
    "voice_features = extract_voice_features(VOICE_TRAIN_PATH, numcep=20)\n",
    "voice_features[\"new\"]= list(map(lambda x,y: np.concatenate((x, y), axis=0), \n",
    "                                voice_features[\"voice_vector\"], dataset[\"im_short\"]))\n",
    "X = np.vstack(voice_features[\"new\"])\n",
    "y=dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9580169145171473 100\n",
      "0.9613771994502365 200\n",
      "0.9620394511058656 300\n",
      "0.9620240478711863 400\n",
      "0.9607125724613503 500\n",
      "0.9620394511058656 600\n",
      "0.9613837134009475 700\n",
      "0.9613572614794789 800\n",
      "0.9620394511058656 900\n",
      "0.9607214617453185 1000\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,1001,100):\n",
    "    mdl_new = GradientBoostingClassifier(n_estimators=i)\n",
    "    print(np.mean(cross_val_score(mdl_new, X, y, cv=5, scoring='accuracy')), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется,что стало получше. Сдадим бустинг в двух вариантах, когда признаков из картинок поменьше, и когда побольше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cep=20;\n",
    "n_est=800;\n",
    "\n",
    "submit_image_features = extract_image_features(IMAGE_TEST_PATH)\n",
    "submit_voice_features = extract_voice_features(VOICE_TEST_PATH, numcep=n_cep)\n",
    "submit_dataset = submit_image_features.merge(\n",
    "    submit_voice_features, \n",
    "    on=\"index\"\n",
    ")\n",
    "submit_dataset[\"index\"] = submit_dataset[\"index\"].apply(int)\n",
    "\n",
    "# voice_features = extract_voice_features(VOICE_TRAIN_PATH, numcep=n_cep)\n",
    "# X = np.vstack(voice_features[\"voice_vector\"])\n",
    "# y=dataset[\"target\"]\n",
    "\n",
    "mdlVoB=GradientBoostingClassifier(n_estimators=n_est)\n",
    "mdlVoB.fit(X,y)\n",
    "\n",
    "submit_dataset[\"im_short\"]=list(map(lambda x: np.extract(mdl_all.feature_importances_>0.003,x),submit_dataset[\"image_vector\"]))\n",
    "submit_dataset[\"new\"]= list(map(lambda x,y: np.concatenate((x, y), axis=0), \n",
    "                                submit_voice_features[\"voice_vector\"], submit_dataset[\"im_short\"]))\n",
    "\n",
    "guess = mdlVoB.predict(np.vstack(submit_dataset[\"new\"]))\n",
    "submit_dataset[\"target\"] = guess\n",
    "\n",
    "submit_dataset[[\"index\", \"target\"]] \\\n",
    "    .sort_values(\"index\") \\\n",
    "    .to_csv(\"sub_boost03.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"im_short\"]=list(map(lambda x: np.extract(mdl_all.feature_importances_>0.005,x),dataset[\"image_vector\"]))\n",
    "voice_features = extract_voice_features(VOICE_TRAIN_PATH, numcep=20)\n",
    "voice_features[\"new\"]= list(map(lambda x,y: np.concatenate((x, y), axis=0), \n",
    "                                voice_features[\"voice_vector\"], dataset[\"im_short\"]))\n",
    "X = np.vstack(voice_features[\"new\"])\n",
    "y=dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cep=20;\n",
    "n_est=800;\n",
    "\n",
    "submit_image_features = extract_image_features(IMAGE_TEST_PATH)\n",
    "submit_voice_features = extract_voice_features(VOICE_TEST_PATH, numcep=n_cep)\n",
    "submit_dataset = submit_image_features.merge(\n",
    "    submit_voice_features, \n",
    "    on=\"index\"\n",
    ")\n",
    "submit_dataset[\"index\"] = submit_dataset[\"index\"].apply(int)\n",
    "\n",
    "# voice_features = extract_voice_features(VOICE_TRAIN_PATH, numcep=n_cep)\n",
    "# X = np.vstack(voice_features[\"voice_vector\"])\n",
    "# y=dataset[\"target\"]\n",
    "\n",
    "mdlVoB=GradientBoostingClassifier(n_estimators=n_est)\n",
    "mdlVoB.fit(X,y)\n",
    "\n",
    "submit_dataset[\"im_short\"]=list(map(lambda x: np.extract(mdl_all.feature_importances_>0.005,x),submit_dataset[\"image_vector\"]))\n",
    "submit_dataset[\"new\"]= list(map(lambda x,y: np.concatenate((x, y), axis=0), \n",
    "                                submit_voice_features[\"voice_vector\"], submit_dataset[\"im_short\"]))\n",
    "\n",
    "guess = mdlVoB.predict(np.vstack(submit_dataset[\"new\"]))\n",
    "submit_dataset[\"target\"] = guess\n",
    "\n",
    "submit_dataset[[\"index\", \"target\"]] \\\n",
    "    .sort_values(\"index\") \\\n",
    "    .to_csv(\"sub_boost05.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не фиксировал seed, примерно такое решение дало 10 место в Private Liderboard, arruracy=0.968."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас на Public части выходит 11-13 место, результат: 0.972."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
